{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumptions:**\n",
    "1. It is possible to detect each instance of roof side separately;\n",
    "2. It is possible to group separate roof polygons into one bulding accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an input image, we first use a VGG-16 without tail layers as the CNN backbone to extract skip features with the size of the input image (see Fig. 2).\n",
    "Meanwhile, the FPN also takes features from different layers of the backbone to construct a feature pyramid and predicts multiple bounding boxes containing the buildings.\n",
    "For a single building, with the skip feature map and its bounding box, followed by RoIAlign, the local features F are obtained. We apply convolutional layers to the feature in order to generate a heat-map mask of building boundaries\n",
    "B that delineate the object of interest. This is followed by additional convolutional layers outputting a mask of candidate keypoints, denoted by V . Both B and V have a size equal to 1/8 the size of the input image. Among all candidate keypoints, we select those w points with the highest score in V as starting point y0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN outputs yt’s potential location P(yt+1|yt, yt−1, y0) at each step t. We input both, yt and yt−1 to compute the conditional probability distribution of yt+1 because it allows defining a unique direction. If given two neighboring vertices with an order\n",
    "in a polygon, the next vertex in this polygon is uniquely determined. Note that the distribution also involves the end signal <eos> (end of sequence), which indicates that the polygon reaches a closed shape and the prediction procedure should come to the end. The final, end vertex in a polygon thus corresponds to the very first, starting vertex y0, which therefore has to be included at each step.\n",
    "In practice, we ultimately concatenate F, B, V , y0 (also y−1 for polygon prediction in the case of roads) and feed the resulting tensor to a multi-layer RNN with ConvLSTM cells in order to sequentially predict the vertices that will delineate the object of interest, until it predicts the <eos> symbol. For buildings, we simply connect all sequentially predicted vertices to obtain the final building polygon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/source/fig1.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
